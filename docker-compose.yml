
# ==========================
# Docker Compose - AG Cloud
# ==========================

# version: "3.9"

# --------------------------
# Networks
# --------------------------
networks:
  ag_cloud:
    driver: bridge
  # storage_minionet:
  #   external: true
  #   name: storage_with_mqtt_minionet


# --------------------------
# Volumes
# --------------------------
volumes:
  postgres_data:
  wal_archive:
  backups:
  gui_data:
  minio-hot-data: {}
  minio-cold-data: {}

# ==========================
# Services
# ==========================
services:

  # --------------------------
  # RelDB / Postgres
  # --------------------------
  postgres:
    build: ./RelDB
    container_name: postgres
    environment:
      POSTGRES_USER: missions_user
      POSTGRES_PASSWORD: pg123
      POSTGRES_DB: missions_db
      PGHOST: 127.0.0.1
      PGPORT: 5432
      PGDATA: /var/lib/postgresql/data
      WAL_DIR: /var/lib/postgresql/wal_archive
      BACKUP_DIR: /var/lib/postgresql/backups
      RETENTION: 7
      TZ: Asia/Jerusalem
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - wal_archive:/var/lib/postgresql/wal_archive
      - backups:/var/lib/postgresql/backups
    healthcheck:
      test: ["CMD", "pg_isready", "-U", "missions_user", "-d", "missions_db"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s
    networks:
      - ag_cloud
    restart: unless-stopped

  postgres_exporter:
    image: quay.io/prometheuscommunity/postgres-exporter:v0.15.0
    environment:
      DATA_SOURCE_NAME: "postgresql://missions_user:pg123@postgres:5432/missions_db?sslmode=disable"
    command:
      - "--extend.query-path=/etc/postgres-queries.yml"
    volumes:
      - ./RelDB/graphs/postgres-queries.yml:/etc/postgres-queries.yml
    depends_on:
      - postgres
    ports:
      - "9187:9187"
    networks:
      - ag_cloud

  # --------------------------
  # MQTT / Kafka / Connect
  # --------------------------
  kafka:
    build: 
      context: ./mqtt_and_kafka/kafka
      dockerfile: dockerfile
    container_name: kafka
    environment:
      - ALLOW_PLAINTEXT_LISTENER=yes
      - KAFKA_ENABLE_KRAFT=yes
      - KAFKA_CFG_PROCESS_ROLES=broker,controller
      - KAFKA_CFG_NODE_ID=1
      - KAFKA_CFG_CONTROLLER_LISTENER_NAMES=CONTROLLER
      - KAFKA_CFG_CONTROLLER_QUORUM_VOTERS=1@kafka:9093
      - KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT,CONTROLLER:PLAINTEXT
      - KAFKA_CFG_LISTENERS=INTERNAL://:9092,EXTERNAL://:9094,CONTROLLER://:9093
      - KAFKA_CFG_ADVERTISED_LISTENERS=INTERNAL://kafka:9092,EXTERNAL://localhost:29092
      - KAFKA_CFG_INTER_BROKER_LISTENER_NAME=INTERNAL
      - KAFKA_CFG_AUTO_CREATE_TOPICS_ENABLE=false
      - KAFKA_CFG_OFFSETS_TOPIC_REPLICATION_FACTOR=1
      - KAFKA_CFG_TRANSACTION_STATE_LOG_REPLICATION_FACTOR=1
      - KAFKA_CFG_TRANSACTION_STATE_LOG_MIN_ISR=1
    ports:
      - "9092:9092"
      - "29092:29092"
    networks:
      - ag_cloud
    healthcheck:
      test: ["CMD-SHELL", "/opt/bitnami/kafka/bin/kafka-topics.sh --bootstrap-server localhost:9092 --list >/dev/null 2>&1 || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 20

  mosquitto:
    image: eclipse-mosquitto:2.0
    container_name: mosquitto
    command: ["mosquitto", "-c", "/mqtt_and_kafka/mosquitto/config/mosquitto.conf"]
    ports:
      - "1883:1883"
    volumes:
      - ./mqtt_and_kafka/mosquitto/config:/mqtt_and_kafka/mosquitto/config:ro
    depends_on:
      kafka:
        condition: service_healthy
    networks:
      - ag_cloud
    healthcheck:
      test: ["CMD", "mosquitto_sub", "-h", "localhost", "-p", "1883", "-t", "$$SYS/#", "-C", "1", "-W", "15"]
      interval: 10s
      timeout: 5s
      retries: 12

  connect:
    build:
      context: ./mqtt_and_kafka
      dockerfile: connect.Dockerfile
    image: local/connect-with-mqtt:1.0.0
    container_name: connect
    depends_on:
      kafka:
        condition: service_healthy
      mosquitto:
        condition: service_healthy
    ports:
      - "8083:8083"
    environment:
      - CONNECT_BOOTSTRAP_SERVERS=kafka:9092
      - CONNECT_GROUP_ID=agcloud-connect
      - CONNECT_CONFIG_STORAGE_TOPIC=_connect_configs
      - CONNECT_OFFSET_STORAGE_TOPIC=_connect_offsets
      - CONNECT_STATUS_STORAGE_TOPIC=_connect_status
      - CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR=1
      - CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR=1
      - CONNECT_STATUS_STORAGE_REPLICATION_FACTOR=1
      - CONNECT_KEY_CONVERTER=org.apache.kafka.connect.storage.StringConverter
      - CONNECT_VALUE_CONVERTER=org.apache.kafka.connect.storage.StringConverter
      - CONNECT_REST_ADVERTISED_HOST_NAME=localhost
      - CONNECT_PLUGIN_PATH=/usr/share/java,/usr/share/confluent-hub-components
    networks:
      - ag_cloud
    healthcheck:
      test: ["CMD", "curl", "-sf", "http://localhost:8083/connectors"]
      interval: 10s
      timeout: 5s
      retries: 12

  init-connector:
    image: curlimages/curl:8.7.1
    depends_on:
      connect:
        condition: service_healthy
    volumes:
      - ./mqtt_and_kafka/connectors:/connectors
    networks:
      - ag_cloud
    entrypoint: >
      sh -c "
        echo '==> Creating MQTT connector...';
        curl -X POST -H 'Content-Type: application/json' --data @/connectors/mqtt-source.json http://connect:8083/connectors;
        echo '==> Done.';
      "

  # --------------------------
  # GUI / Runner / Gateway
  # --------------------------
  runner:
    build:
      context: ./GUI
      dockerfile: src/vast/runner/Dockerfile
      args:
        USE_NETFREE: ${USE_NETFREE:-true}
    container_name: runner
    environment:
      - RUNNER_MODE=real
      - SQLITE_DB=/data/app.db
      - LOG_LEVEL=INFO
    volumes:
      - ./GUI/data:/data:ro
    ports:
      - "50051:50051"
    restart: unless-stopped

  gateway:
    container_name: gateway
    build:
      context: ./GUI
      dockerfile: src/vast/gateway/Dockerfile
      args:
        USE_NETFREE: ${USE_NETFREE:-true}
    environment:
      - RUNNER_ADDR=runner:50051
    ports:
      - "8000:8000"
    depends_on:
      - runner
    restart: unless-stopped

  sensors_metrics:
    build:
      context: ./GUI
      dockerfile: src/vast/services/Dockerfile
    container_name: sensors_metrics
    environment:
      - SQLITE_DB=/data/app.db
      - GATEWAY_URL=http://gateway:8000
    volumes:
      - ./GUI/data:/data:ro
    depends_on:
      - gateway
    networks:
      - ag_cloud
    restart: unless-stopped

  # --------------------------
  # Prometheus / Grafana
  # --------------------------
  prometheus:
    image: prom/prometheus:latest
    volumes:
      - ./prometheus/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - ./prometheus/prometheus-recording.rules.yml:/etc/prometheus/prometheus-recording.rules.yml:ro
      - ./prometheus/postgres-alerts.yml:/etc/prometheus/postgres-alerts.yml:ro
    ports:
      - "9090:9090"
    depends_on:
      - postgres_exporter
      - minio-hot
      - minio-cold
    networks:
      - ag_cloud

  grafana:
    image: grafana/grafana-oss:latest
    environment:
      GF_SECURITY_ALLOW_EMBEDDING: "true"
      GF_AUTH_ANONYMOUS_ENABLED: "true"
      GF_AUTH_ANONYMOUS_ORG_ROLE: Viewer
      GF_USERS_DEFAULT_THEME: light
      GF_SECURITY_ADMIN_USER: admin
      GF_SECURITY_ADMIN_PASSWORD: admin
    volumes:
      - ./grafana/dashboards:/var/lib/grafana/dashboards:ro
      - ./grafana/provisioning:/etc/grafana/provisioning:ro
    ports:
      - "3000:3000"
    depends_on:
      - prometheus
    networks:
      - ag_cloud

  # --------------------------
  # Desktop App
  # --------------------------
  desktop_app:
    build:
      context: ./GUI
      dockerfile: src/vast/desktop/Dockerfile
    container_name: desktop_app
    environment:
      - NO_VNC_PORT=8080
      - DISPLAY=host.docker.internal:0.0
      - GATEWAY_URL=http://sensors_metrics:8000
    ports:
      - "5900:5900"
      - "8080:8080"
    depends_on:
      - db_api_service 
    volumes:
        - ./GUI/src/vast:/app/src/vast
    networks:
      - ag_cloud
    restart: unless-stopped


  # --------------------------
  # Large Mosquitto
  # --------------------------
  large-mosquitto:
    container_name: large-mosquitto
    image: eclipse-mosquitto:2
    restart: unless-stopped
    volumes:
      - ./storage_with_mqtt/mqtt_images/mosquitto/mosquitto.conf:/mosquitto/config/mosquitto.conf
    ports:
      - "1885:1885"
    networks:
      - ag_cloud

  # --------------------------
  # MinIO: hot + cold + bootstrap
  # --------------------------
  minio-hot:
    build:
      context: ./storage_with_mqtt/storage/minio-storage
    container_name: minio-hot
    environment:
      MINIO_PROMETHEUS_AUTH_TYPE: public
      MINIO_ROOT_USER: minioadmin
      MINIO_ROOT_PASSWORD: minioadmin123
    ports:
      - "9001:9000"   # HOT S3
      - "9002:9001"   # HOT Console
    networks: [ag_cloud]
    healthcheck:
      test: ["CMD", "curl", "-fsS", "http://localhost:9000/minio/health/ready"]
      interval: 3s
      timeout: 2s
      retries: 40
    volumes:
      - minio-hot-data:/data

  minio-cold:
    build:
      context: ./storage_with_mqtt/storage/minio-storage
    container_name: minio-cold
    environment:
      MINIO_PROMETHEUS_AUTH_TYPE: public
      MINIO_ROOT_USER: minioadmin
      MINIO_ROOT_PASSWORD: minioadmin123
    ports:
      - "9101:9000"   # COLD S3
      - "9102:9001"   # COLD Console
    networks: [ag_cloud]
    healthcheck:
      test: ["CMD", "curl", "-fsS", "http://localhost:9000/minio/health/ready"]
      interval: 3s
      timeout: 2s
      retries: 40
    volumes:
      - minio-cold-data:/data

  mc-bootstrap:
    build:
      context: ./storage_with_mqtt/storage/Lifecycle_rules/minio-bootstrap
    volumes:
      - ./storage_with_mqtt/storage/combined_minio_setup/config:/config:ro
      - ./storage_with_mqtt/data/config:/config
    depends_on:
      minio-hot:
        condition: service_healthy
      minio-cold:
        condition: service_healthy
    command: ["/bin/bash","-lc","/entrypoint/init.sh; tail -f /dev/null"]
    environment:
      MINIO_ROOT_USER: minioadmin
      MINIO_ROOT_PASSWORD: minioadmin123
      HOT_ENDPOINT: http://minio-hot:9000
      COLD_ENDPOINT: http://minio-cold:9000
      MC_ALIAS_HOT: hot
      MC_ALIAS_COLD: cold
      BUCKET_IMAGERY: imagery
      BUCKET_TELEMETRY: telemetry
    networks: [ag_cloud]
    restart: unless-stopped

  # --------------------------
  # MQTT Ingest & Publisher
  # --------------------------
  mqtt_ingest:
    build:
      context: ./storage_with_mqtt/mqtt_images/mqtt_ingest
    container_name: mqtt_ingest
    environment:
      MINIO_ENDPOINT: http://minio-hot:9000
      MINIO_ROOT_USER: minioadmin
      MINIO_ROOT_PASSWORD: minioadmin123
      BUCKET_IMAGERY: imagery
      BUCKET_TELEMETRY: telemetry
      MQTT_BROKER: large-mosquitto
      MQTT_PORT: 1885
      MQTT_TOPIC: MQTT/imagery/#
      MQTT_PUB_TOPIC: imagery/ingested
      DUMMY_DB: 0
      DB_API_BASE: http://db_api_service:8001
      DB_API_TOKEN: auto
      OUTBOX_DIR: /app/outbox
      DB_API_AUTH_MODE: service
      DB_API_SERVICE_NAME: mqtt_ingest
      INGEST_WORKERS: 8
    volumes:
      - ./storage_with_mqtt/mqtt_images/outbox:/app/outbox
    depends_on:
      large-mosquitto:
        condition: service_started
      minio-hot:
        condition: service_healthy
      mc-bootstrap:
        condition: service_started
      db_api_service:
        condition: service_started
    networks:
      - ag_cloud
    restart: unless-stopped

  mqtt_publisher:
    build:
      context: ./storage_with_mqtt/mqtt_images/mqtt_publisher
    container_name: mqtt_publisher
    environment:
      - MQTT_HOST=large-mosquitto
      - MQTT_PORT=1885
      - MQTT_TOPIC_BASE=MQTT/imagery
      - IMAGES_DIR=/images
      - CAMERA_ID=camera-01
      - LIMIT=0
      - SHUFFLE=1
      - MQTT_QOS=2
      - PUBLISH_DELAY_MS=100
    volumes:
      - ./storage_with_mqtt/mqtt_images/data/real_images:/images:ro
    depends_on:
      - large-mosquitto
      - mqtt_ingest
    networks:
      - ag_cloud

  # --------------------------
  # DB API Service
  # --------------------------
  db_api_service:
    build: ./services/db_api_service
    container_name: db_api_service
    environment:
      DB_DSN: postgresql+psycopg://missions_user:pg123@host.docker.internal:5432/missions_db
      ENV: dev
      JWT_SECRET: change-me-please-very-secret
      JWT_ALGO: HS256
      ACCESS_TTL_MIN: 15
      REFRESH_TTL_DAYS: 14
      DEV_SA_NAME: my-ingest-service
    ports:
      - "8001:8001"
    networks:
      - ag_cloud
    restart: unless-stopped
    depends_on:
      - postgres

  
  # --------------------------
  # Flink JobManager & TaskManager
  # --------------------------
  flink-jobmanager:
    build:
      context: ./streaming/flink
      dockerfile: Dockerfile.flink-py
    image: agcloud-flink-py:1.18    
    container_name: flink-jobmanager
    command: jobmanager
    ports:
      - "8081:8081"
    networks: [ag_cloud]
    environment:
      - |
        FLINK_PROPERTIES=
        jobmanager.rpc.address: flink-jobmanager
        parallelism.default: 2
        taskmanager.numberOfTaskSlots: 2
        jobmanager.memory.process.size: 1600m
        taskmanager.memory.process.size: 1728m
        s3.endpoint: http://minio-hot:9000
        s3.path.style.access: true
        s3.access.key: minioadmin
        s3.secret.key: minioadmin123
        fs.s3a.connection.ssl.enabled: false
        python.client.executable: /usr/bin/python3
        python.executable: /usr/bin/python3
      - HTTP_INFER_URL=http://fruit-inference-http:8000/infer_json
    volumes:
      - ./streaming/flink/jobs:/opt/flink/jobs:ro
      - ./streaming/flink/connectors/flink-json-1.18.1.jar:/opt/flink/lib/flink-json-1.18.1.jar:ro
      - ./streaming/flink/connectors/flink-sql-connector-kafka-3.2.0-1.18.jar:/opt/flink/lib/flink-sql-connector-kafka-3.2.0-1.18.jar:ro
      - ./streaming/flink/connectors/flink-connector-kafka-3.2.0-1.18.jar:/opt/flink/lib/flink-connector-kafka-3.2.0-1.18.jar:ro
      - ./streaming/flink/connectors/kafka-clients-3.2.3.jar:/opt/flink/lib/kafka-clients-3.2.3.jar:ro
      - ./streaming/flink/connectors/lz4-java-1.8.0.jar:/opt/flink/lib/lz4-java-1.8.0.jar:ro
      - ./streaming/flink/connectors/snappy-java-1.1.10.5.jar:/opt/flink/lib/snappy-java-1.1.10.5.jar:ro
    restart: unless-stopped


  flink-taskmanager:
    image: agcloud-flink-py:1.18
    container_name: flink-taskmanager
    command: taskmanager
    depends_on:
      flink-jobmanager:
        condition: service_started
    networks: [ag_cloud]
    environment:
      - |
        FLINK_PROPERTIES=
        jobmanager.rpc.address: flink-jobmanager
        parallelism.default: 2
        taskmanager.numberOfTaskSlots: 2
        jobmanager.memory.process.size: 1600m
        taskmanager.memory.process.size: 1728m
        s3.endpoint: http://minio-hot:9000
        s3.path.style.access: true
        s3.access.key: minioadmin
        s3.secret.key: minioadmin123
        fs.s3a.connection.ssl.enabled: false
        python.client.executable: /usr/bin/python3
        python.executable: /usr/bin/python3
      - HTTP_INFER_URL=http://fruit-inference-http:8000/infer_json
    volumes:
      - ./streaming/flink/connectors/flink-json-1.18.1.jar:/opt/flink/lib/flink-json-1.18.1.jar:ro
      - ./streaming/flink/connectors/flink-sql-connector-kafka-3.2.0-1.18.jar:/opt/flink/lib/flink-sql-connector-kafka-3.2.0-1.18.jar:ro
      - ./streaming/flink/connectors/flink-connector-kafka-3.2.0-1.18.jar:/opt/flink/lib/flink-connector-kafka-3.2.0-1.18.jar:ro
      - ./streaming/flink/connectors/kafka-clients-3.2.3.jar:/opt/flink/lib/kafka-clients-3.2.3.jar:ro
      - ./streaming/flink/connectors/lz4-java-1.8.0.jar:/opt/flink/lib/lz4-java-1.8.0.jar:ro
      - ./streaming/flink/connectors/snappy-java-1.1.10.5.jar:/opt/flink/lib/snappy-java-1.1.10.5.jar:ro
    restart: unless-stopped



  # --------------------------
  # Inference HTTP Service
  # --------------------------

  fruit-inference-http:
    build:
      context: ./services/inference_http   
      dockerfile: Dockerfile
    environment:
    - TEAM=fruit
    - WEIGHTS_PATH=/app/weights/fruit_cls_best.ts
    - MINIO_ENDPOINT=minio-hot:9000
    - MINIO_ACCESS_KEY=minioadmin
    - MINIO_SECRET_KEY=minioadmin123
    - MINIO_SECURE=0
    volumes:
      - ./services/inference_http/weights:/app/weights:ro
    container_name: fruit-inference-http
    networks: [ag_cloud]
    ports:
      - "8011:8000"
    restart: unless-stopped

  
  # --------------------------
  # Flink Jobs
  # --------------------------
  flink-dispatcher-fruit:
    image: agcloud-flink-py:1.18
    container_name: flink-dispatcher-fruit
    depends_on:
      flink-jobmanager: { condition: service_started }
      flink-taskmanager: { condition: service_started }
      fruit-inference-http: { condition: service_started }
    networks: [ag_cloud]
    environment:
      - KAFKA_BOOTSTRAP=kafka:9092
      - INPUT_TOPIC=imagery.new.fruit
      - TEAM=fruit
      - HTTP_URL=http://fruit-inference-http:8000/infer_json
      - DLQ_TOPIC=dlq.inference.http
      - GROUP_ID=http-dispatcher-fruit
      - PARALLELISM=2
      - PYFLINK_CLIENT_EXECUTABLE=/usr/bin/python3
    volumes:
      - ./streaming/flink/jobs:/opt/flink/jobs:ro
      - ./streaming/flink/connectors/flink-connector-kafka-3.2.0-1.18.jar:/opt/flink/lib/flink-connector-kafka-3.2.0-1.18.jar:ro
      - ./streaming/flink/connectors/flink-sql-connector-kafka-3.2.0-1.18.jar:/opt/flink/lib/flink-sql-connector-kafka-3.2.0-1.18.jar:ro
      - ./streaming/flink/connectors/flink-json-1.18.1.jar:/opt/flink/lib/flink-json-1.18.1.jar:ro
      - ./streaming/flink/connectors/kafka-clients-3.2.3.jar:/opt/flink/lib/kafka-clients-3.2.3.jar:ro
      - ./streaming/flink/connectors/lz4-java-1.8.0.jar:/opt/flink/lib/lz4-java-1.8.0.jar:ro
      - ./streaming/flink/connectors/snappy-java-1.1.10.5.jar:/opt/flink/lib/snappy-java-1.1.10.5.jar:ro
    command: [
      "bash","-lc",
      "set -e;
      echo 'Waiting for JobManager to accept commands...';
      until /opt/flink/bin/flink list --jobmanager flink-jobmanager:8081 >/dev/null 2>&1; do
        echo 'still waiting...'; sleep 3;
      done;
      echo 'JobManager is ready!';
      /opt/flink/bin/flink run \
        -Dpython.client.executable=/usr/bin/python3 \
        -Dpython.executable=/usr/bin/python3 \
        -Dpipeline.jars=file:///opt/flink/lib/flink-connector-kafka-3.2.0-1.18.jar,file:///opt/flink/lib/flink-sql-connector-kafka-3.2.0-1.18.jar,file:///opt/flink/lib/flink-json-1.18.1.jar \
        --jobmanager flink-jobmanager:8081 \
        --detached \
        --python /opt/flink/jobs/http_dispatcher.py \
        -- \
          --bootstrap kafka:9092 \
          --input-topic imagery.new.fruit \
          --team fruit \
          --http-url http://fruit-inference-http:8000/infer_json \
          --group-id http-dispatcher-fruit \
          --dlq-topic dlq.inference.http;
      tail -f /dev/null"
    ]
